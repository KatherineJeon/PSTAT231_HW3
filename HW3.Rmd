---
title: "HW3"
output: html_document
date: '2022-04-17'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Importing data and loading necessary packages.
```{r}
titanic <- read.csv(file = 'data/titanic.csv')
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(corrr)
library(discrim)
set.seed(45)
```

Changing some variables into factors.
```{r}
titanic$survived <- factor(titanic$survived, levels = c('Yes', 'No'))
titanic$pclass <- factor(titanic$pclass)
levels(titanic$survived)
```


## Question 1

```{r}
titanic_split <- initial_split(titanic, prop = 0.8,
                                strata = survived)
titanic_train <- training(titanic_split)
titanic_test <- testing(titanic_split)
```

```{r}
head(titanic_train)
```

```{r}
sum(is.na(titanic_train))
mean(is.na(titanic_train))
```


Since we are trying to train the model to predict 'survived' factor, We need to see each data with the same ratio with the original data.

## Question 2

```{r}
ggplot(titanic_train, aes(x = survived)) + geom_bar()
```


## Question 3
```{r}
cor_titanic <- titanic_train %>%
  select(is.numeric) %>%
  correlate()
cor_titanic
```

```{r}
rplot(cor_titanic)
```



## Question 4

```{r}
titanic_recipe <- recipe(survived ~ pclass + sex + age + sib_sp + parch + fare , data = titanic_train) %>%
  step_impute_linear(age) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = ~ starts_with("sex"):fare + age:fare)
```


## Question 5

```{r}
glm_model <- logistic_reg() %>% 
  set_engine("glm") %>%
  set_mode("classification")

glm_model
```

```{r}
glm_wflow <- workflow() %>% 
  add_model(glm_model) %>% 
  add_recipe(titanic_recipe)

glm_fit <- fit(glm_wflow, titanic_train)
glm_fit %>%
  tidy()
```


## Question 6

```{r}
lda_mod <- discrim_linear() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")

lda_wkflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(titanic_recipe)

lda_fit <- fit(lda_wkflow, titanic_train)
```


## Question 7

```{r}
qda_mod <- discrim_quad() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")

qda_wkflow <- workflow() %>% 
  add_model(qda_mod) %>% 
  add_recipe(titanic_recipe)

qda_fit <- fit(qda_wkflow, titanic_train)
```


## Question 8

```{r}
library(klaR)
nb_mod <- naive_Bayes() %>% 
  set_mode("classification") %>% 
  set_engine("klaR") %>% 
  set_args(usekernel = FALSE) 

nb_wkflow <- workflow() %>% 
  add_model(nb_mod) %>% 
  add_recipe(titanic_recipe)

nb_fit <- fit(nb_wkflow, titanic_train)
```


## Question 9

```{r}
log_reg_acc <- augment(glm_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)

lda_acc <- augment(lda_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)

qda_acc <- augment(qda_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)

nb_acc <- augment(nb_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)



accuracies <- c(log_reg_acc$.estimate, lda_acc$.estimate, 
                nb_acc$.estimate, qda_acc$.estimate)
models <- c("Logistic Regression", "LDA", "Naive Bayes", "QDA")
results <- tibble(accuracies = accuracies, models = models)
results %>% 
  arrange(-accuracies)
```


## Question 10

```{r}
predict(glm_fit, new_data = titanic_test, type = "prob")

multi_metric <- metric_set(accuracy, sensitivity, specificity)

augment(nb_fit, new_data = titanic_test) %>%
  multi_metric(truth = survived, estimate = .pred_class)


augment(glm_fit, new_data = titanic_test) %>%
  roc_curve(survived, .pred_Yes) %>%
  autoplot()
```


## Question 11
$$
\begin{aligned}
p &= \frac{e^z} {1 + e^z} \\
&= 1 - \frac{1} {1 + e^z} \\
1 - p &= \frac{1} {1 + e^z} \\
1 + e^z &= \frac{1} {1 - p}  = \frac{1 -p} {1-p} + \frac{p} {1 - p}\\
e^z &= \frac{p} {1-p} \\
z &= log\frac{p} {1 - p} \\
z(p) &= ln(\frac{p} {1 - p})
\end{aligned}
$$


## Question 12
